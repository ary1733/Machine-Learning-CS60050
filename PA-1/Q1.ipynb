{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming Assignment 1 Q1\n",
    "### Decision Tree\n",
    "\n",
    "Group Number : 46\n",
    "\n",
    "Student 1 : Aryan Singh 19CS30007\n",
    "\n",
    "Student 2 : Seemant Guruprasad Achari 19CS30057\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A constant to reference the result column\n",
    "LABEL = 'Response'\n",
    "\n",
    "# Data read using pandas\n",
    "df = pd.read_csv('Dataset_C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset index\n",
    "def train_test_split(df,train_sample=0.5,target_col= LABEL):\n",
    "    all_indexes=[]\n",
    "    df_grouped= df.groupby(target_col)\n",
    "    for x,x_df in df_grouped:\n",
    "        t = x_df.sample(frac=train_sample,).index\n",
    "        all_indexes.append(t)\n",
    "    g = all_indexes[0].values\n",
    "    for k in all_indexes[1:]:\n",
    "        g=np.hstack([g,k.values])\n",
    "        #np.hstack([all_indexes[0].values,all_indexes[1].values])\n",
    "\n",
    "    train_df = df[df.index.isin(g) ]\n",
    "    test_df = df[~df.index.isin(g)]\n",
    "    return train_df, test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(df, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    92454\n",
      "1    12898\n",
      "Name: Response, dtype: int64\n",
      "0    23113\n",
      "1     3224\n",
      "Name: Response, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set[LABEL].value_counts())\n",
    "print(test_set[LABEL].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>33536</td>\n",
       "      <td>26</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>28619</td>\n",
       "      <td>152</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>27496</td>\n",
       "      <td>152</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2630</td>\n",
       "      <td>160</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23367</td>\n",
       "      <td>152</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "1   2    Male   76                1            3                   0   \n",
       "3   4    Male   21                1           11                   1   \n",
       "4   5  Female   29                1           41                   1   \n",
       "5   6  Female   24                1           33                   0   \n",
       "6   7    Male   23                1           11                   0   \n",
       "\n",
       "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n",
       "1    1-2 Year             No           33536                    26      183   \n",
       "3    < 1 Year             No           28619                   152      203   \n",
       "4    < 1 Year             No           27496                   152       39   \n",
       "5    < 1 Year            Yes            2630                   160      176   \n",
       "6    < 1 Year            Yes           23367                   152      249   \n",
       "\n",
       "   Response  \n",
       "1         0  \n",
       "3         0  \n",
       "4         0  \n",
       "5         0  \n",
       "6         0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the Top five rows of the Data\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute => Gender has 2 unique values.[ Male, Female, ]\n",
      "Attribute => Age has 66 unique values.\n",
      "Attribute => Driving_License has 2 unique values.[ 1, 0, ]\n",
      "Attribute => Region_Code has 53 unique values.\n",
      "Attribute => Previously_Insured has 2 unique values.[ 0, 1, ]\n",
      "Attribute => Vehicle_Age has 3 unique values.[ > 2 Years, 1-2 Year, < 1 Year, ]\n",
      "Attribute => Vehicle_Damage has 2 unique values.[ Yes, No, ]\n",
      "Attribute => Annual_Premium has 36617 unique values.\n",
      "Attribute => Policy_Sales_Channel has 140 unique values.\n",
      "Attribute => Vintage has 290 unique values.\n",
      "Label     => Response has 2 unique values.[ 1, 0, ]\n"
     ]
    }
   ],
   "source": [
    "# Finding the Discrete Valued attributes in the dataset\n",
    "\n",
    "# max unique categories to consider\n",
    "MAX_UNIQUE_CATEGORIES = 20\n",
    "for k in df.columns:\n",
    "    if k == 'id':\n",
    "        continue\n",
    "    if k == LABEL :\n",
    "        print(\"Label     => \", end = \"\")\n",
    "    else:\n",
    "        print(\"Attribute => \", end = \"\")\n",
    "    print(f\"{k} has {len(df[k].unique())} unique values.\", end=\"\")\n",
    "    if(len(df[k].unique()) <= MAX_UNIQUE_CATEGORIES):\n",
    "        print(\"[ \", end = \"\")\n",
    "        for val in df[k].unique():\n",
    "            print(val, end = \", \")\n",
    "        print(\"]\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attr Gender is categorical\n",
      "Attr Age is continuous\n",
      "Attr Driving_License is categorical\n",
      "Attr Region_Code is continuous\n",
      "Attr Previously_Insured is categorical\n",
      "Attr Vehicle_Age is categorical\n",
      "Attr Vehicle_Damage is categorical\n",
      "Attr Annual_Premium is continuous\n",
      "Attr Policy_Sales_Channel is continuous\n",
      "Attr Vintage is continuous\n"
     ]
    }
   ],
   "source": [
    "CATEGORICAL_FEATURE = \"categorical\"\n",
    "CONTINUOUS_FEATURE = \"continuous\"\n",
    "def determineTypeOfFeature(df):\n",
    "    \n",
    "    feature_types = {}\n",
    "    n_unique_values_treshold = MAX_UNIQUE_CATEGORIES\n",
    "    for feature in df.columns:\n",
    "        if feature == 'id':\n",
    "            continue\n",
    "        if feature != LABEL:\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types[feature] = CATEGORICAL_FEATURE\n",
    "            else:\n",
    "                feature_types[feature] = CONTINUOUS_FEATURE\n",
    "    \n",
    "    return feature_types\n",
    "FEATURE_TYPES = determineTypeOfFeature(df)\n",
    "for k, v in FEATURE_TYPES.items():\n",
    "    print(f\"Attr {k} is {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "POTENTIAL_SPLIT_LIMIT = 10\n",
    "def getPotentialSplits(featureName, trainData):\n",
    "    \n",
    "    potential_splits = []\n",
    "    values = trainData[featureName]\n",
    "    unique_values = np.unique(values)\n",
    "    \n",
    "    type_of_feature = FEATURE_TYPES[featureName]\n",
    "    if type_of_feature == CONTINUOUS_FEATURE:\n",
    "        for index in range(len(unique_values)):\n",
    "            if index != 0:\n",
    "                current_value = unique_values[index]\n",
    "                previous_value = unique_values[index - 1]\n",
    "                potential_split = (current_value + previous_value) / 2\n",
    "                \n",
    "                potential_splits.append(potential_split)\n",
    "        \n",
    "        # Since the potential_splits can have thousands of options, we need to drop some of them to reduce the complexity\n",
    "        if(len(potential_splits) > POTENTIAL_SPLIT_LIMIT):\n",
    "            # startIdx = 0\n",
    "            endIdx = len(potential_splits)\n",
    "            incrementBy = (endIdx + POTENTIAL_SPLIT_LIMIT -1)// POTENTIAL_SPLIT_LIMIT\n",
    "            # reducedPotentialList = [potential_splits[idx] for idx in range(startIdx, endIdx, incrementBy)]\n",
    "            potential_splits = potential_splits[::incrementBy]\n",
    "    # feature is categorical\n",
    "    # (there need to be at least 2 unique values, otherwise in the\n",
    "    # split_data function data_below would contain all data points\n",
    "    # and data_above would be empty)\n",
    "    else:\n",
    "        potential_splits = unique_values\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.5, 39.5, 68.5, 97.5, 126.5, 155.5, 184.5, 213.5, 242.5, 271.5]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPotentialSplits('Vintage', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesList(trainData, featureSet):\n",
    "    featuresList = []\n",
    "    for key, value in FEATURE_TYPES.items():\n",
    "        if key not in featureSet:\n",
    "            continue\n",
    "        if(value == CONTINUOUS_FEATURE):\n",
    "            potentialSplits = getPotentialSplits(key, trainData)\n",
    "            for potentialSplit in potentialSplits:\n",
    "                featuresList.append([key, potentialSplit])\n",
    "        else:\n",
    "            featuresList.append([key])\n",
    "    \n",
    "    return featuresList  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to Calulate Total Entropy\n",
    "\n",
    "# Input : Traning Data, label, classList\n",
    "\n",
    "def calculateTotalEntropy(trainData, label, classList):\n",
    "    totalCount = trainData.shape[0]\n",
    "\n",
    "    totalEntropy = 0\n",
    "\n",
    "    for c in classList:\n",
    "        # Count the number of data points which satify == c class constraints\n",
    "        totalClassCount = trainData[trainData[label] == c].shape[0]\n",
    "        # Calulate the class's entropy\n",
    "        totalClassEntropy = 0\n",
    "        prob = totalClassCount / totalCount\n",
    "        if( prob >0):\n",
    "            totalClassEntropy = - (prob)*np.log2(prob)\n",
    "        # Accumulate the class's entropy into the totalEntropy\n",
    "        totalEntropy = totalEntropy + totalClassEntropy\n",
    "    \n",
    "    return totalEntropy\n",
    "\n",
    "def calculateEntropy(featureValueData, label, classList):\n",
    "    classCount = featureValueData.shape[0]\n",
    "    entropy = 0\n",
    "\n",
    "    for c in classList:\n",
    "        # Count the number of data points withing the featureValueData which satify == c class constraints\n",
    "        labelClassCount = featureValueData[featureValueData[label] == c].shape[0]\n",
    "        classEntropy = 0\n",
    "        if labelClassCount != 0:\n",
    "            # if labelClassCount != 0 then calculate its entropy\n",
    "            prob = labelClassCount/classCount\n",
    "            if prob !=0:\n",
    "                classEntropy = -prob * np.log2(prob)\n",
    "        # Accumulate its entropy\n",
    "        entropy = entropy + classEntropy\n",
    "    return entropy\n",
    "\n",
    "def calulateInformationGain(feature, trainData, label, classList):\n",
    "    featureName = feature[0]\n",
    "    threshold = None\n",
    "\n",
    "    # featureValueList = getPotentialSplits(featureName, trainData)\n",
    "    # featureValueList = trainData[featureName].unique() # here UPDATE\n",
    "\n",
    "    totalCount = trainData.shape[0]\n",
    "    featureInfo = 0.0\n",
    "        \n",
    "    if(FEATURE_TYPES[featureName] == CONTINUOUS_FEATURE):\n",
    "        # For cases when value <= threshold\n",
    "        threshold = feature[1]\n",
    "        featureValueData = trainData[trainData[featureName] <= threshold]\n",
    "        featureValueCount = featureValueData.shape[0]\n",
    "        featureValueEntropy = calculateEntropy(featureValueData, label, classList)\n",
    "        featureValueProbability = featureValueCount / totalCount\n",
    "        featureInfo += featureValueProbability * featureValueEntropy\n",
    "\n",
    "        # For cases when value > threshold\n",
    "        featureValueData = trainData[trainData[featureName] > threshold]\n",
    "        featureValueCount = featureValueData.shape[0]\n",
    "        featureValueEntropy = calculateEntropy(featureValueData, label, classList)\n",
    "        featureValueProbability = featureValueCount / totalCount\n",
    "        featureInfo += featureValueProbability * featureValueEntropy\n",
    "    else:\n",
    "        featureValueList = trainData[featureName].unique()\n",
    "        for featureValue in featureValueList:\n",
    "            featureValueData = trainData[trainData[featureName] == featureValue]\n",
    "            featureValueCount = featureValueData.shape[0]\n",
    "            featureValueEntropy = calculateEntropy(featureValueData, label, classList)\n",
    "            featureValueProbability = featureValueCount / totalCount\n",
    "            featureInfo += featureValueProbability * featureValueEntropy\n",
    "    \n",
    "    totalEntropy = calculateTotalEntropy(trainData, label, classList)\n",
    "\n",
    "    gain = totalEntropy - featureInfo\n",
    "    \n",
    "    return gain \n",
    "\n",
    "def findMostImportantFeature(trainData, featureList, label, classList):\n",
    "    # featureList = trainData.columns.drop(label) # Since label is not a feature\n",
    "    # featureList = getFeaturesList(trainData) \n",
    "    \n",
    "    maxInfoGain = -1 # init with smallest value possible\n",
    "    maxInfoFeature = None\n",
    "    # features are of two types: \n",
    "    # 1) Categorical, in which you iterate over multiple value of that feature\n",
    "    # 2) Continous converted into binary category, i/p<= threshold or ip>threshold\n",
    "    for feature in featureList:\n",
    "        featureInfoGain = calulateInformationGain(feature, trainData, label, classList)\n",
    "        # print(feature, featureInfoGain, maxInfoGain)\n",
    "        if float(featureInfoGain) > float(maxInfoGain):\n",
    "            maxInfoGain = featureInfoGain\n",
    "            maxInfoFeature = feature\n",
    "    return maxInfoFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entropy of Complete Data Set with Response as label = 0.5362909567366381\n"
     ]
    }
   ],
   "source": [
    "print(f\"The entropy of Complete Data Set with {LABEL} as label = {calculateTotalEntropy(df, LABEL, df[LABEL].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1147977301372255"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calulateInformationGain(['Previously_Insured',298.5], df, LABEL, df[LABEL].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4327494857191425e-07"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calulateInformationGain(['Vintage',150.5], df, LABEL, df[LABEL].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calulateInformationGain(['Age',2900], df, LABEL, df[LABEL].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131689 entries, 0 to 131688\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   id                    131689 non-null  int64 \n",
      " 1   Gender                131689 non-null  object\n",
      " 2   Age                   131689 non-null  int64 \n",
      " 3   Driving_License       131689 non-null  int64 \n",
      " 4   Region_Code           131689 non-null  int64 \n",
      " 5   Previously_Insured    131689 non-null  int64 \n",
      " 6   Vehicle_Age           131689 non-null  object\n",
      " 7   Vehicle_Damage        131689 non-null  object\n",
      " 8   Annual_Premium        131689 non-null  int64 \n",
      " 9   Policy_Sales_Channel  131689 non-null  int64 \n",
      " 10  Vintage               131689 non-null  int64 \n",
      " 11  Response              131689 non-null  int64 \n",
      "dtypes: int64(9), object(3)\n",
      "memory usage: 12.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Gender', 'categorical'), ('Age', 'continuous'), ('Driving_License', 'categorical'), ('Region_Code', 'continuous'), ('Previously_Insured', 'categorical'), ('Vehicle_Age', 'categorical'), ('Vehicle_Damage', 'categorical'), ('Annual_Premium', 'continuous'), ('Policy_Sales_Channel', 'continuous'), ('Vintage', 'continuous')])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_TYPES.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class for decision node and tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  passing same feature list\n",
    "\n",
    "class DecisionNode:\n",
    "    nodeId = 0\n",
    "    def __init__(self, featureSet, label, classList, decisionNodeName, depth, max_depth):\n",
    "        # print(depth, decisionNodeName)\n",
    "        self.nodeId = DecisionNode.nodeId\n",
    "        DecisionNode.nodeId += 1\n",
    "        self.featureSet = featureSet\n",
    "        # print(f\"Cur feature set{self.featureSet}\")\n",
    "        self.decisionNodeName = decisionNodeName\n",
    "        self.label = label\n",
    "        self.classList = classList\n",
    "        self.leafNode = False\n",
    "        self.isPruned = False\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        if( self.depth == max_depth ):\n",
    "            self.isPruned = True\n",
    "    \n",
    "    def fitData(self, trainData):\n",
    "        label = self.label\n",
    "        classList = self.classList\n",
    "        self.featureList = getFeaturesList(trainData, self.featureSet)\n",
    "        self.labelDistribution = {}\n",
    "        for c in self.classList:\n",
    "            cnt = trainData[trainData[label]==c].shape[0]\n",
    "            self.labelDistribution[c] = cnt\n",
    "        # print(self.labelDistribution )\n",
    "        self.trainDataCount = trainData.shape[0]\n",
    "        self.currentNodeReturnVal = trainData[label].mode()[0]  # return this if you cant decide\n",
    "        self.inpurity = calculateTotalEntropy(trainData, label, classList)\n",
    "        # print(f\"Impurity = {self.inpurity} @depth = {self.depth}\")\n",
    "        if(self.labelDistribution[0]==0 or self.labelDistribution[1] == 0 or self.isPruned):\n",
    "            self.leafNode = True\n",
    "\n",
    "        self.childrenNode = {}\n",
    "        if(not self.leafNode):\n",
    "            label = self.label\n",
    "            classList = self.classList\n",
    "            retVal = findMostImportantFeature(trainData, self.featureList, label, classList)\n",
    "            if(retVal == None):\n",
    "                self.leafNode = True\n",
    "                self.decisionNodeName = self.decisionNodeName\n",
    "                self.bestFeatureName = \"Ans = \" + str(self.currentNodeReturnVal)\n",
    "                return\n",
    "            self.bestFeatureName = retVal[0]\n",
    "            # print(self.bestFeatureName)\n",
    "            newFeatureSet = self.featureSet.copy()\n",
    "            # newFeatureSet.remove(self.bestFeatureName)\n",
    "            if(FEATURE_TYPES[self.bestFeatureName] == CONTINUOUS_FEATURE):\n",
    "                self.threshold = retVal[1]\n",
    "                # print(f\"threshold = {self.threshold}\")\n",
    "                # left is <= threshold\n",
    "                nextNodeName = self.bestFeatureName + \" <= \" + str(self.threshold)\n",
    "                # print(f\"The next node will go by the name {nextNodeName}\")\n",
    "                node = DecisionNode(newFeatureSet, self.label, self.classList, nextNodeName, self.depth + 1, self.max_depth)\n",
    "                node.fitData(trainData[trainData[self.bestFeatureName] <= self.threshold])\n",
    "                self.childrenNode[True] = (node)\n",
    "\n",
    "                # right is > threshold\n",
    "                nextNodeName = self.bestFeatureName + \" > \" + str(self.threshold)\n",
    "                # print(f\"The next node will go by the name {nextNodeName}\")\n",
    "                node = DecisionNode(newFeatureSet, self.label, self.classList, nextNodeName, self.depth + 1, self.max_depth)\n",
    "                node.fitData(trainData[trainData[self.bestFeatureName] > self.threshold])\n",
    "                self.childrenNode[False] = (node)\n",
    "\n",
    "            else:\n",
    "                attributeValues = trainData[self.bestFeatureName].unique()\n",
    "                for nextValue in attributeValues:\n",
    "                    nextNodeName = self.bestFeatureName + \" == \" + str(nextValue)\n",
    "                    # print(f\"The next node will go by the name {nextNodeName}\")\n",
    "                    node = DecisionNode(newFeatureSet, self.label, self.classList, nextNodeName, self.depth + 1, self.max_depth)\n",
    "                    node.fitData(trainData[trainData[self.bestFeatureName] == nextValue])\n",
    "                    # print(node)\n",
    "                    self.childrenNode[nextValue] = node\n",
    "\n",
    "        else:\n",
    "            \n",
    "            self.decisionNodeName = self.decisionNodeName\n",
    "            self.bestFeatureName = \"Ans = \" + str(self.currentNodeReturnVal)\n",
    "    def predict(self, x_hat):\n",
    "        if(self.leafNode or self.isPruned):\n",
    "            # returning the majority decision\n",
    "            return self.currentNodeReturnVal\n",
    "        # we need to traverse down the tree\n",
    "        if(FEATURE_TYPES[self.bestFeatureName] == CONTINUOUS_FEATURE):\n",
    "            nextNode = (x_hat[self.bestFeatureName] <= self.threshold)\n",
    "        else:\n",
    "            nextNode = x_hat[self.bestFeatureName]\n",
    "        if(nextNode not in self.childrenNode.keys()):\n",
    "            # print(self.bestFeatureName)\n",
    "            # print(f\"xhat = {x_hat}\")\n",
    "            # print(f\"nextNode = {nextNode}\")\n",
    "            # print(f\"childrenNode = {self.childrenNode.keys()}\")\n",
    "            return self.currentNodeReturnVal\n",
    "        return self.childrenNode[nextNode].predict(x_hat)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Name: {self.decisionNodeName}\\nData Count: {self.trainDataCount}\\nFeature: {self.bestFeatureName}\\nChildren: {len(self.childrenNode)}\\n\"\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, featureSet, label, classList, rootName, max_depth):\n",
    "        DecisionNode.nodeId = 0\n",
    "        self.max_depth = max_depth\n",
    "        self.root= DecisionNode(featureSet, LABEL, classList, rootName, 0, max_depth)\n",
    "        self.treeDepth = 0\n",
    "    def fitData(self, trainData):\n",
    "        self.root.fitData(trainData)\n",
    "    def predict(self, x):\n",
    "        return self.root.predict(x)\n",
    "    def getTreeDepth(self):\n",
    "        maxDepthTillNow = 0\n",
    "        node = self.root\n",
    "        st = [node]\n",
    "\n",
    "        while(len(st)>0):\n",
    "            node = st.pop()\n",
    "            maxDepthTillNow = max(maxDepthTillNow, node.depth)\n",
    "            if(node.leafNode):\n",
    "                continue\n",
    "            for key in node.childrenNode:\n",
    "                st.append(node.childrenNode[key])\n",
    "        return maxDepthTillNow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureList = getFeaturesList(train_set)\n",
    "featureSet = set(FEATURE_TYPES.keys())\n",
    "tree= DecisionTree(featureSet, LABEL, train_set[LABEL].unique(), \"Root\", 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fitData(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# outputs = {\n",
    "#     0: 0,\n",
    "#     1: 0\n",
    "# }\n",
    "# total_samples = 0\n",
    "# for index, row in test_set.iterrows():\n",
    "#     y_hat = root.predict(row)\n",
    "#     outputs[y_hat] += 1\n",
    "#     cnt +=  (y_hat == row[LABEL])\n",
    "#     total_samples +=1\n",
    "#     # print(f\"pediction = {root.predict(row)}, Real ={row[LABEL]}\")\n",
    "# print(cnt)\n",
    "# print(outputs)\n",
    "# print(f\"Acc = {cnt / total_samples}\")\n",
    "# print(self.bestFeatureName, x_hat, nextNode, self.childrenNode.keys())\n",
    "\n",
    "def GetAccuracy(tree:DecisionTree, test_set, printDetails = True):\n",
    "    cnt = 0\n",
    "    outputs = {\n",
    "        0: 0,\n",
    "        1: 0\n",
    "    }\n",
    "    total_samples = 0\n",
    "    root = tree.root\n",
    "    for index, row in test_set.iterrows():\n",
    "        y_hat = root.predict(row)\n",
    "        outputs[y_hat] += 1\n",
    "        cnt +=  (y_hat == row[LABEL])\n",
    "        total_samples +=1\n",
    "        # print(f\"pediction = {root.predict(row)}, Real ={row[LABEL]}\")\n",
    "    accuracy = cnt / total_samples\n",
    "    if(printDetails):\n",
    "        print(cnt)\n",
    "        print(outputs)\n",
    "        print(f\"Accuracy = {cnt / total_samples} and Depth = {tree.getTreeDepth()}\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23068\n",
      "{0: 26232, 1: 105}\n",
      "Accuracy = 0.8758780422979079 and Depth = 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8758780422979079"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetAccuracy(tree, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23113\n",
       "1     3224\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[LABEL].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDetail(node:DecisionNode):\n",
    "    return f\"Node id {node.nodeId}\\n {node.bestFeatureName}\"\n",
    "def print_tree(tree:DecisionTree, op_file):\n",
    "        '''\n",
    "            This function prints the decision tree using the graphviz library.\n",
    "            It basically does a bfs on the graph and then appends the nodes one by one.\n",
    "        '''\n",
    "        root = tree.root\n",
    "        my_graph= Digraph('Decision Tree', filename=op_file)\n",
    "        my_graph.attr(rankdir='TD', size='1000,500')\n",
    "\n",
    "        my_graph.attr('node', shape='rectangle')\n",
    "        \n",
    "        # doing a bfs using a queue\n",
    "        qq = [root]                          # using a list as a queue for the bradth first search\n",
    "        while len(qq) > 0:\n",
    "            node = qq.pop(0)         \n",
    "            if node.leafNode:                    # stop if its a leaf node\n",
    "                continue\n",
    "            for _,child in node.childrenNode.items():    # else check its children\n",
    "                my_graph.edge(getDetail(node), getDetail(child), label=child.decisionNodeName)\n",
    "                qq.append(child)\n",
    "\n",
    "        my_graph.render(op_file, view=True)     # open the output file for convenience\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(tree, 'pic.gv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing #0 with splitRatio = 0.6746651465734925\n",
      "Testing tree #0\n",
      "37599\n",
      "{0: 42836, 1: 7}\n",
      "Accuracy = 0.8775996078705973 and Depth = 8\n",
      "\n",
      "Testing #1 with splitRatio = 0.5736114001678966\n",
      "Testing tree #1\n",
      "49256\n",
      "{0: 56130, 1: 20}\n",
      "Accuracy = 0.8772217275155832 and Depth = 8\n",
      "\n",
      "Testing #2 with splitRatio = 0.5410974621211172\n",
      "Testing tree #2\n",
      "53010\n",
      "{0: 60392, 1: 40}\n",
      "Accuracy = 0.8771842732327244 and Depth = 8\n",
      "\n",
      "Testing #3 with splitRatio = 0.7492545538547516\n",
      "Testing tree #3\n",
      "28941\n",
      "{0: 32848, 1: 173}\n",
      "Accuracy = 0.8764422640138094 and Depth = 8\n",
      "\n",
      "Testing #4 with splitRatio = 0.712126354123391\n",
      "Testing tree #4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3616\\1522456776.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Testing tree #{i}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mGetAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3616\\1876190969.py\u001b[0m in \u001b[0;36mGetAccuracy\u001b[1;34m(tree, test_set, printDetails)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[1;33m+=\u001b[0m  \u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLABEL\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3616\\1927756720.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x_hat)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;31m# print(f\"childrenNode = {self.childrenNode.keys()}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrentNodeReturnVal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildrenNode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnextNode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3616\\1927756720.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x_hat)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;31m# print(f\"childrenNode = {self.childrenNode.keys()}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrentNodeReturnVal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildrenNode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnextNode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3616\\1927756720.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x_hat)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;31m# print(f\"childrenNode = {self.childrenNode.keys()}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrentNodeReturnVal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildrenNode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnextNode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3616\\1927756720.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x_hat)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;31m# we need to traverse down the tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFEATURE_TYPES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbestFeatureName\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mCONTINUOUS_FEATURE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mnextNode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbestFeatureName\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mnextNode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbestFeatureName\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Books\\ML\\Assignments\\PA-1\\venv\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Books\\ML\\Assignments\\PA-1\\venv\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Books\\ML\\Assignments\\PA-1\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3357\u001b[0m                     \u001b[1;34m\"backfill or nearest lookups\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3358\u001b[0m                 )\n\u001b[1;32m-> 3359\u001b[1;33m             \u001b[0mcasted_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Books\\ML\\Assignments\\PA-1\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_maybe_cast_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5698\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mint\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mequivalent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5699\u001b[0m         \"\"\"\n\u001b[1;32m-> 5700\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5701\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5702\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Books\\ML\\Assignments\\PA-1\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mis_floating\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2128\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"integer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2130\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_floating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2132\u001b[0m         \"\"\"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trees = []\n",
    "for i in range(10):\n",
    "    # train_set, test_set = train_test_split(df, .8)\n",
    "    splitRatio = np.random.uniform(0.5, .8)\n",
    "    print(f\"Testing #{i} with splitRatio = {splitRatio}\")\n",
    "    train_set, test_set = train_test_split(df, splitRatio)\n",
    "    featureSet = set(FEATURE_TYPES.keys())\n",
    "    tree= DecisionTree(featureSet, LABEL, train_set[LABEL].unique(), f\"Root #{i}\", 8)\n",
    "    tree.fitData(train_set)\n",
    "    print(f\"Testing tree #{i}\")\n",
    "    GetAccuracy(tree, test_set)\n",
    "    trees.append(tree)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruneTree(tree:DecisionTree, validation_set):\n",
    "    maxValAcc = GetAccuracy(tree, validation_set, False)\n",
    "    print(f\"Base Acc = {maxValAcc}\")\n",
    "    node = tree.root\n",
    "    st = [node]\n",
    "\n",
    "    nodeToPrune = None\n",
    "    # print(\"I am here\")\n",
    "    while(len(st)>0):\n",
    "        node = st.pop()\n",
    "        # mark node as pruned\n",
    "        if(node.leafNode):\n",
    "            continue\n",
    "\n",
    "        node.isPruned = True\n",
    "        # evaluate\n",
    "        curAccuracy = GetAccuracy(tree, validation_set, False)\n",
    "        # maxValAcc = max(maxValAcc, curAccuracy)\n",
    "\n",
    "        node.isPruned = False\n",
    "        # print(curAccuracy, node.nodeId)\n",
    "        # print(curAccuracy, maxValAcc, curAccuracy> maxValAcc)\n",
    "        # store node id if better found\n",
    "        if( curAccuracy > maxValAcc):\n",
    "            nodeToPrune = node\n",
    "            print(f\"Increased accuracy from {maxValAcc} to {curAccuracy}\")\n",
    "            maxValAcc = curAccuracy\n",
    "\n",
    "            # remove\n",
    "            # node.isPruned = True\n",
    "            # node.leafNode = True\n",
    "            # return True\n",
    "            # remove\n",
    "        # loop\n",
    "        for key in node.childrenNode:\n",
    "            st.append(node.childrenNode[key])\n",
    "    if(nodeToPrune is not None):\n",
    "        nodeToPrune.isPruned = True\n",
    "        nodeToPrune.leafNode = True\n",
    "        print(f\"Pruned nodeId = {nodeToPrune.nodeId}\")\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set, test_set = train_test_split(df.head(1000), .8)\n",
    "train_set, validation_set = train_test_split(train_set, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet = set(FEATURE_TYPES.keys())\n",
    "tree= DecisionTree(featureSet, LABEL, train_set[LABEL].unique(), \"Root\", 10)\n",
    "tree.fitData(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(tree, 'pic_unpruned.gv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "{0: 138, 1: 22}\n",
      "Accuracy = 0.8625 and Depth = 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8625"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetAccuracy(tree, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Acc = 0.8625\n",
      "Increased accuracy from 0.8625 to 0.875\n",
      "Increased accuracy from 0.875 to 0.8875\n",
      "Pruned nodeId = 2\n",
      "pruned 0\n",
      "Base Acc = 0.8875\n",
      "Increased accuracy from 0.8875 to 0.89375\n",
      "Pruned nodeId = 70\n",
      "pruned 1\n",
      "Base Acc = 0.89375\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "while(pruneTree(tree, validation_set)):\n",
    "    print(f\"pruned {cnt}\")\n",
    "    cnt+=1\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(tree, 'pic_pruned.gv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n",
      "{0: 174, 1: 26}\n",
      "Accuracy = 0.795 and Depth = 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.795"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetAccuracy(tree, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a300604ec19f1262707987b8931cb13819a0956c707061a8a3861e9aea3c0e0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
